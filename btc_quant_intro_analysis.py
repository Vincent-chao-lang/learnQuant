#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
btc_quant_intro_analysis.py

æµæ°´çº¿ï¼š
1) ä» Stooq è·å– BTCUSD æ—¥çº¿æ•°æ® -> æ ‡å‡†åŒ–ä¸º date, price_usd -> åˆå¹¶æ›´æ–°æœ¬åœ° CSV
2) é‡åŒ–åˆ†æï¼ˆç»“æ„/åˆ†å¸ƒ/é£é™©ï¼Œä¸åšæ–¹å‘é¢„æµ‹ï¼‰
3) è¾“å‡ºä¸­æ–‡ Markdown æŠ¥å‘Š + ç›´æ–¹å›¾ï¼ˆå›¾ç‰‡æŒ‰æ—¥æœŸå‘½åï¼Œä¸è¦†ç›–å†å²ï¼‰
4) é‚®ä»¶å‘é€ï¼ˆGmail SMTPï¼‰ï¼šé™„ä»¶åŒ…å« MD + HTMLï¼›è‹¥ pandoc å¯ç”¨åˆ™é™„åŠ  PDF

ä¾èµ–ï¼š
pip install numpy pandas scikit-learn matplotlib requests python-dotenv
ï¼ˆå¯é€‰ï¼‰å®‰è£… pandoc ä»¥ç”Ÿæˆ PDFï¼šbrew install pandoc æˆ– apt install pandoc

.envï¼ˆæ”¾åœ¨è„šæœ¬åŒç›®å½•ï¼Œä¸”åŠ å…¥ .gitignoreï¼‰ï¼š
SMTP_USER=ä½ çš„gmail@gmail.com
SMTP_PASS=ä½ çš„Gmail App Passwordï¼ˆå»æ‰ç©ºæ ¼ï¼‰
TO_EMAIL=æ”¶ä»¶äººé‚®ç®±ï¼ˆå¯å¡«è‡ªå·±ï¼‰
"""

import argparse
import os
import ssl
import smtplib
import subprocess
from dataclasses import dataclass
from datetime import datetime, timezone
from pathlib import Path
from typing import List, Tuple

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import requests

from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.metrics.pairwise import cosine_similarity

# è¯»å– .envï¼ˆå¼ºçƒˆå»ºè®®ï¼‰
try:
    from dotenv import load_dotenv
    load_dotenv()
except Exception:
    # æ²¡è£… python-dotenv ä¹Ÿèƒ½è·‘ï¼Œåªæ˜¯éœ€è¦ä½ ç”¨ export è®¾ç½®ç¯å¢ƒå˜é‡
    pass


# ----------------------------
# 0) å°å·¥å…·ï¼šMarkdown è¡¨æ ¼ï¼ˆä¸ä¾èµ– tabulateï¼‰
# ----------------------------
def df_to_md_table(df: pd.DataFrame, max_rows: int = 12) -> str:
    df = df.head(max_rows).copy()
    cols = list(df.columns)
    lines = []
    lines.append("| " + " | ".join(map(str, cols)) + " |")
    lines.append("| " + " | ".join(["---"] * len(cols)) + " |")
    for _, row in df.iterrows():
        vals = []
        for v in row.values:
            if isinstance(v, float):
                vals.append(f"{v:.6g}")
            else:
                vals.append(str(v))
        lines.append("| " + " | ".join(vals) + " |")
    return "\n".join(lines)


def ensure_dir(p: Path) -> None:
    p.mkdir(parents=True, exist_ok=True)


# ----------------------------
# 1) æ•°æ®æ›´æ–°ï¼šStooq -> æ ‡å‡†åŒ– -> åˆå¹¶ CSV
# ----------------------------
def fetch_btcusd_daily_from_stooq(timeout: int = 30) -> pd.DataFrame:
    """
    Stooq æ—¥çº¿ CSVï¼š
    https://stooq.com/q/d/l/?s=btcusd&i=d

    å¸¸è§åˆ—ï¼šDate, Open, High, Low, Close, Volume
    æˆ‘ä»¬åªç”¨ Close ä½œä¸º price_usdï¼Œå¹¶æ ‡å‡†åŒ–è¾“å‡ºï¼šdate, price_usd
    """
    url = "https://stooq.com/q/d/l/?s=btcusd&i=d"
    resp = requests.get(url, timeout=timeout)
    resp.raise_for_status()

    from io import StringIO
    raw = pd.read_csv(StringIO(resp.text))

    # ç»Ÿä¸€åˆ—åä¸ºå°å†™ï¼Œå…¼å®¹ Date/Close ç­‰å¤§å°å†™
    raw.columns = [c.strip().lower() for c in raw.columns]
    if "date" not in raw.columns or "close" not in raw.columns:
        raise RuntimeError(f"Stooq CSV ç¼ºå°‘ date/close åˆ—ï¼Œå®é™…åˆ—ï¼š{list(raw.columns)}")

    df = raw[["date", "close"]].copy()
    df.rename(columns={"close": "price_usd"}, inplace=True)

    df["date"] = pd.to_datetime(df["date"], errors="coerce")
    df["price_usd"] = pd.to_numeric(df["price_usd"], errors="coerce")
    df = df.dropna().sort_values("date").reset_index(drop=True)
    return df

def get_local_last_date(csv_path: Path) -> pd.Timestamp | None:
    if not csv_path.exists():
        return None
    local = pd.read_csv(csv_path, parse_dates=["date"]).sort_values("date")
    if local.empty:
        return None
    return local["date"].iloc[-1]

def fetch_btcusd_daily_increment_from_coingecko(
    last_date: pd.Timestamp | None,
    timeout: int = 60,
) -> pd.DataFrame:
    """
    CoinGecko å…è´¹å¤‡æºï¼ˆä¸å¸¦ keyï¼‰ï¼š
    - åªæ‹‰æœ€è¿‘ 2 å¤© market_chart
    - æŒ‰ UTC æ—¥æœŸèšåˆæˆæ—¥åºåˆ—ï¼ˆæ¯ä¸€å¤©å–æœ€åä¸€ä¸ªä»·æ ¼ç‚¹ï¼‰
    - å¦‚æœ last_date ç»™äº†ï¼Œå°±åªè¿”å› > last_date çš„å¢é‡
    è¾“å‡ºæ ‡å‡†ï¼šdate, price_usd
    """
    url = "https://api.coingecko.com/api/v3/coins/bitcoin/market_chart"
    params = {"vs_currency": "usd", "days": 2}  # åªå–æœ€è¿‘ 2 å¤©
    resp = requests.get(url, params=params, timeout=timeout)
    resp.raise_for_status()

    data = resp.json()
    prices = data.get("prices", [])
    if not prices:
        return pd.DataFrame(columns=["date", "price_usd"])

    df = pd.DataFrame(prices, columns=["ts_ms", "price_usd"])
    # ç”¨ UTC æ¥åˆ’åˆ†â€œå“ªä¸€å¤©â€ï¼Œé¿å…æœ¬åœ°æ—¶åŒºå¯¼è‡´è·¨æ—¥é”™ä½
    df["date"] = pd.to_datetime(df["ts_ms"], unit="ms", utc=True).dt.date
    df["date"] = pd.to_datetime(df["date"])
    df = (
        df.sort_values("ts_ms")
          .groupby("date", as_index=False)["price_usd"]
          .last()
          .sort_values("date")
          .reset_index(drop=True)
    )

    if last_date is not None:
        df = df[df["date"] > last_date].reset_index(drop=True)

    return df[["date", "price_usd"]]

# def safe_fetch_btcusd_increment_from_coingecko(last_date, timeout=60) -> pd.DataFrame:
#     try:
#         return fetch_btcusd_daily_increment_from_coingecko(last_date=last_date, timeout=timeout)
#     except Exception as e:
#         # ä¸è®©å¤‡æºå¤±è´¥å½±å“ä¸»æµç¨‹
#         print(f"âš ï¸ CoinGecko å¤‡æºå¤±è´¥ï¼ˆå°†è·³è¿‡å¢é‡è¡¥é½ï¼‰ï¼š{type(e).__name__}: {e}")
#         return pd.DataFrame(columns=["date", "price_usd"])

import time
import random

def safe_fetch_btcusd_increment_from_coingecko(last_date, timeout=60) -> pd.DataFrame:
    for attempt in range(3):
        try:
            return fetch_btcusd_daily_increment_from_coingecko(last_date=last_date, timeout=timeout)
        except Exception as e:
            wait = (2 ** attempt) + random.random()
            print(f"âš ï¸ CoinGecko å¤‡æºå¤±è´¥ï¼ˆç¬¬{attempt+1}/3æ¬¡ï¼‰ï¼š{type(e).__name__}: {e}ï¼›{wait:.1f}såé‡è¯•")
            time.sleep(wait)
    print("âš ï¸ CoinGecko å¤‡æºè¿ç»­å¤±è´¥ï¼Œè·³è¿‡å¢é‡è¡¥é½ï¼Œç»§ç»­ä½¿ç”¨æœ¬åœ°æ•°æ®")
    return pd.DataFrame(columns=["date", "price_usd"])


def fetch_btcusd_daily_primary_with_backup(csv_path: Path, timeout: int = 30) -> pd.DataFrame:
    """
    ä¸»æºï¼šStooqï¼ˆå…¨é‡ï¼Œæ ‡å‡†åŒ–åè¿”å›ï¼‰
    å¤‡æºï¼šCoinGecko å…è´¹æ¥å£ï¼ˆä»…å¢é‡ï¼Œè¿”å›æœ€è¿‘æ–°å¢æ—¥æœŸï¼‰
    è¾“å‡ºç»Ÿä¸€ï¼šdate, price_usd
    """
    try:
        df = fetch_btcusd_daily_from_stooq(timeout=timeout)
        print("âœ… æ•°æ®æºï¼šStooqï¼ˆä¸»æºï¼‰")
        return df
    except Exception as e:
        print(f"âš ï¸ Stooq è·å–å¤±è´¥ï¼Œåˆ‡æ¢ CoinGeckoï¼ˆå…è´¹å¤‡æºï¼Œä»…å¢é‡ï¼‰ã€‚åŸå› ï¼š{e}")
        last_date = get_local_last_date(csv_path)
        inc = fetch_btcusd_daily_increment_from_coingecko(last_date=last_date, timeout=max(60, timeout))
        print(f"âœ… æ•°æ®æºï¼šCoinGeckoï¼ˆå…è´¹å¤‡æºï¼‰å¢é‡è¡Œæ•°ï¼š{len(inc)}")
        return inc


# def update_price_csv(csv_path: Path) -> Tuple[pd.DataFrame, bool]:
#     """
#     æ›´æ–°æœ¬åœ° CSVï¼ˆæ ‡å‡† schemaï¼šdate, price_usdï¼‰
#     - CSV ä¸å­˜åœ¨ï¼šä¸‹è½½å…¨é‡å¹¶ä¿å­˜
#     - CSV å­˜åœ¨ï¼šä¸‹è½½å…¨é‡å merge å»é‡ï¼ˆå°æ•°æ®é‡æ›´ç¨³ï¼‰
#     è¿”å›ï¼š(æœ€æ–° df, æ˜¯å¦å‘ç”Ÿå†™å…¥æ›´æ–°)
#     """
#     remote = fetch_btcusd_daily_primary_with_backup(csv_path)

#     if not csv_path.exists():
#         ensure_dir(csv_path.parent)
#         remote.to_csv(csv_path, index=False)
#         return remote, True

#     local = pd.read_csv(csv_path, parse_dates=["date"]).sort_values("date").reset_index(drop=True)
#     if "price_usd" not in local.columns:
#         raise RuntimeError(f"æœ¬åœ° CSV ä¸æ˜¯æ ‡å‡†æ ¼å¼ï¼ˆç¼ºå°‘ price_usdï¼‰ï¼š{csv_path}")

#     merged = (
#         pd.concat([local, remote], ignore_index=True)
#         .drop_duplicates(subset=["date"], keep="last")
#         .sort_values("date")
#         .reset_index(drop=True)
#     )

#     updated = (len(merged) != len(local)) or (merged["date"].iloc[-1] != local["date"].iloc[-1])
#     if updated:
#         merged.to_csv(csv_path, index=False)

#     return merged, updated


def update_price_csv(csv_path: Path) -> tuple[pd.DataFrame, bool, str]:
    """
    è¿”å›ï¼š(æœ€æ–°df, æ˜¯å¦æ›´æ–°, æœ¬æ¬¡æ•°æ®æºè¯´æ˜)
    è§„åˆ™ï¼š
      - é»˜è®¤ç”¨ Stooq å…¨é‡ mergeï¼ˆç¨³ï¼‰
      - å¦‚æœ Stooq è¯·æ±‚å¤±è´¥ï¼šç”¨ CoinGecko å…è´¹å¢é‡è¡¥
      - å¦‚æœ Stooq æˆåŠŸä½†â€œæ²¡æ–°å¢æ—¥æœŸâ€ï¼ˆå‘¨æœ«å¸¸è§ï¼‰ï¼šä¹Ÿå°è¯•ç”¨ CoinGecko å…è´¹å¢é‡è¡¥
        ï¼ˆè¿™æ ·å‘¨æœ«ä¹Ÿèƒ½è¡¥åˆ°æ–°æ—¥çº¿ç‚¹ï¼‰
    """
    source_note = "stooq"

    last_date = get_local_last_date(csv_path)

    # 1) å…ˆå°è¯• Stooq
    stooq_df = None
    try:
        stooq_df = fetch_btcusd_daily_from_stooq(timeout=30)
    except Exception as e:
        stooq_df = None
        stooq_err = e

    # 2) å¦‚æœæœ¬åœ°ä¸å­˜åœ¨ï¼Œä¼˜å…ˆç”¨å¯ç”¨çš„å…¨é‡ï¼ˆStooqï¼‰ï¼Œå¦åˆ™ç”¨ CoinGeckoï¼ˆä¼šè¾ƒå°‘ä½†è‡³å°‘èƒ½èµ·ï¼‰
    if not csv_path.exists():
        ensure_dir(csv_path.parent)
        if stooq_df is not None and not stooq_df.empty:
            stooq_df.to_csv(csv_path, index=False)
            return stooq_df, True, "stooq(ä¸»æº)"
        inc = fetch_btcusd_daily_increment_from_coingecko(last_date=None, timeout=60)
        inc.to_csv(csv_path, index=False)
        return inc, True, "coingecko(å¤‡æº-å¢é‡)"

    # 3) è¯»å–æœ¬åœ°
    local = pd.read_csv(csv_path, parse_dates=["date"]).sort_values("date").reset_index(drop=True)
    if "price_usd" not in local.columns:
        raise RuntimeError(f"æœ¬åœ° CSV ç¼ºå°‘ price_usdï¼š{csv_path}")

    local_last = local["date"].iloc[-1] if not local.empty else None

    # 4) Stooq æˆåŠŸï¼šmerge å…¨é‡
    if stooq_df is not None and not stooq_df.empty:
        merged = (
            pd.concat([local, stooq_df], ignore_index=True)
              .drop_duplicates(subset=["date"], keep="last")
              .sort_values("date")
              .reset_index(drop=True)
        )
        updated = (len(merged) != len(local)) or (merged["date"].iloc[-1] != local_last)

        # 4a) å¦‚æœ Stooq æ²¡æ–°å¢ï¼ˆå‘¨æœ«å¸¸è§ï¼‰ï¼Œå°è¯•ç”¨ CoinGecko å¢é‡è¡¥
        #     ç›®çš„ï¼šå‘¨æœ«ä¹Ÿå°½é‡è¡¥åˆ°â€œæ–°çš„ä¸€å¤©â€
        if not updated:
            #inc = fetch_btcusd_daily_increment_from_coingecko(last_date=local_last, timeout=60)
            inc = safe_fetch_btcusd_increment_from_coingecko(last_date=local_last, timeout=60)
            if not inc.empty:
                merged2 = (
                    pd.concat([merged, inc], ignore_index=True)
                      .drop_duplicates(subset=["date"], keep="last")
                      .sort_values("date")
                      .reset_index(drop=True)
                )
                updated2 = (len(merged2) != len(merged)) or (merged2["date"].iloc[-1] != merged["date"].iloc[-1])
                if updated2:
                    merged2.to_csv(csv_path, index=False)
                    return merged2, True, "coingecko(å‘¨æœ«å¤‡æº-å¢é‡)"
            else:
                return merged, False, "stooq(ä¸»æºï¼›å‘¨æœ«å¯èƒ½æ— æ›´æ–°)"
        # æ­£å¸¸å†™å›ï¼ˆStooq æœ‰å˜åŒ–ï¼‰
        if updated:
            merged.to_csv(csv_path, index=False)
        return merged, updated, "stooq(ä¸»æº)"

    # 5) Stooq å¤±è´¥ï¼šç”¨ CoinGecko å¢é‡è¡¥
    inc = fetch_btcusd_daily_increment_from_coingecko(last_date=local_last, timeout=60)
    if inc.empty:
        # å…œåº•ï¼šStooq å¤±è´¥ + CoinGecko ä¹Ÿæ²¡å–åˆ°æ–°å¢ï¼Œå°±è¿”å›åŸæ•°æ®ä½†æ ‡è®°åŸå› 
        return local, False, f"coingecko(å¤‡æº-æ— æ–°å¢ï¼›stooqå¤±è´¥:{type(stooq_err).__name__})"
    merged = (
        pd.concat([local, inc], ignore_index=True)
          .drop_duplicates(subset=["date"], keep="last")
          .sort_values("date")
          .reset_index(drop=True)
    )
    merged.to_csv(csv_path, index=False)
    return merged, True, "coingecko(å¤‡æº-å¢é‡ï¼›stooqå¤±è´¥)"


# ----------------------------
# 2) åˆ†æï¼šç‰¹å¾ã€ç›¸ä¼¼è¡Œæƒ…ã€èšç±»çŠ¶æ€ã€é£é™©è¯†åˆ«
# ----------------------------
def load_and_features(csv_path: Path) -> pd.DataFrame:
    """
    è¾“å…¥ CSV å¿…é¡»åŒ…å«åˆ—ï¼šdate, price_usd
    è¾“å‡ºåŒ…å« ret/vol/trend ç­‰ç‰¹å¾ï¼Œdropna åç”¨äºåˆ†æ
    """
    df = pd.read_csv(csv_path, parse_dates=["date"]).sort_values("date").reset_index(drop=True)
    if "price_usd" not in df.columns:
        raise ValueError("CSV å¿…é¡»åŒ…å«åˆ—ï¼šprice_usdï¼ˆæœ¬è„šæœ¬ä¼šåœ¨æ›´æ–°é˜¶æ®µä¿è¯ï¼‰")

    df["price_usd"] = df["price_usd"].astype(float)
    df["log_price"] = np.log(df["price_usd"])
    df["ret"] = df["log_price"].diff()  # æ—¥å¯¹æ•°æ”¶ç›Š

    df["vol_7d"] = df["ret"].rolling(7).std()
    df["vol_30d"] = df["ret"].rolling(30).std()

    df["ma_30"] = df["price_usd"].rolling(30).mean()
    df["trend_30d"] = df["price_usd"] / df["ma_30"] - 1

    df = df.dropna().reset_index(drop=True)
    if len(df) < 80:
        raise ValueError(f"æœ‰æ•ˆæ ·æœ¬å¤ªçŸ­ï¼ˆ{len(df)} è¡Œï¼‰ï¼Œå»ºè®®è‡³å°‘ 80 å¤©ä»¥ä¸Š")
    return df


def basic_summary(df: pd.DataFrame) -> pd.DataFrame:
    ret = df["ret"].dropna()
    vol30 = df["vol_30d"].dropna()
    out = {
        "å¼€å§‹æ—¥æœŸ": df["date"].iloc[0].date(),
        "ç»“æŸæ—¥æœŸ": df["date"].iloc[-1].date(),
        "æ ·æœ¬å¤©æ•°": len(df),
        "æ—¥å¯¹æ•°æ”¶ç›Šå‡å€¼": float(ret.mean()),
        "æ—¥å¯¹æ•°æ”¶ç›Šä¸­ä½æ•°": float(ret.median()),
        "æ—¥æ”¶ç›Šä¸ºæ­£æ¯”ä¾‹(èƒœç‡)": float((ret > 0).mean()),
        "30æ—¥å¹´åŒ–æ³¢åŠ¨å‡å€¼(â‰ˆ)": float(vol30.mean() * np.sqrt(365)),
    }
    return pd.DataFrame([out])


def build_window_matrix(df: pd.DataFrame, window: int) -> Tuple[np.ndarray, np.ndarray]:
    feats = ["ret", "vol_7d", "trend_30d"]
    X, start_idx = [], []
    for i in range(len(df) - window):
        w = df.iloc[i:i + window][feats].values
        X.append(w.flatten())
        start_idx.append(i)
    return np.asarray(X), np.asarray(start_idx)


@dataclass
class SimilarPack:
    table: pd.DataFrame
    dist: pd.DataFrame
    hist_path: Path


def similar_windows_future_dist(
    df: pd.DataFrame,
    out_dir: Path,
    report_date: str,
    window: int = 20,
    topk: int = 12,
    horizon: int = 10,
) -> SimilarPack:
    X, start_idx = build_window_matrix(df, window=window)
    scaler = StandardScaler()
    Xs = scaler.fit_transform(X)

    q = Xs[-1].reshape(1, -1)
    sims = cosine_similarity(q, Xs)[0]

    idx_sorted = np.argsort(sims)[::-1]
    idx_sorted = idx_sorted[idx_sorted != (len(Xs) - 1)]
    top = idx_sorted[:topk]

    rows = []
    for j in top:
        i = int(start_idx[j])
        w_start = df.iloc[i]["date"].date()
        w_end = df.iloc[i + window - 1]["date"].date()

        future_slice = df.iloc[i + window:i + window + horizon]
        if len(future_slice) < horizon:
            continue
        future_ret = float(future_slice["ret"].sum())

        rows.append({
            "ç›¸ä¼¼çª—å£å¼€å§‹": w_start,
            "ç›¸ä¼¼çª—å£ç»“æŸ": w_end,
            "ç›¸ä¼¼åº¦": float(sims[j]),
            f"æœªæ¥{horizon}å¤©å¯¹æ•°æ”¶ç›Š": future_ret
        })

    table = pd.DataFrame(rows).sort_values("ç›¸ä¼¼åº¦", ascending=False).reset_index(drop=True)
    if table.empty:
        raise RuntimeError("ç›¸ä¼¼çª—å£ç»“æœä¸ºç©ºï¼šå¯èƒ½æ•°æ®å¤ªçŸ­æˆ– horizon/window å‚æ•°è¿‡å¤§")

    col = f"æœªæ¥{horizon}å¤©å¯¹æ•°æ”¶ç›Š"
    vals = table[col].values

    dist = pd.DataFrame([{
        "æ ·æœ¬æ•°": int(len(vals)),
        "å‡å€¼": float(np.mean(vals)),
        "æ ‡å‡†å·®": float(np.std(vals, ddof=1)) if len(vals) > 1 else float("nan"),
        "æœ€å°å€¼(min)": float(np.min(vals)),
        "10%åˆ†ä½(p10)": float(np.quantile(vals, 0.10)),
        "ä¸­ä½æ•°(p50)": float(np.quantile(vals, 0.50)),
        "90%åˆ†ä½(p90)": float(np.quantile(vals, 0.90)),
        "æœ€å¤§å€¼(max)": float(np.max(vals)),
        "èƒœç‡(>0)": float(np.mean(vals > 0)),
    }])

    ensure_dir(out_dir)
    hist_path = out_dir / f"future_hist_{report_date}.png"

    # è§£å†³ä¸­æ–‡å­—ä½“ warningï¼šå°½é‡é€‰ç³»ç»Ÿå¯ç”¨å­—ä½“ï¼ˆä¸ä¼šå› ç¼ºå­—ä½“è€Œå¤±è´¥ï¼‰
    plt.rcParams["font.sans-serif"] = ["PingFang SC", "Heiti SC", "Microsoft YaHei", "SimHei", "Arial Unicode MS", "DejaVu Sans"]
    plt.rcParams["axes.unicode_minus"] = False

    plt.figure()
    plt.hist(vals, bins=min(12, max(5, len(vals))))
    plt.axvline(np.mean(vals))
    plt.title(f"ç›¸ä¼¼è¡Œæƒ…ä¸‹æœªæ¥{horizon}å¤©æ”¶ç›Šåˆ†å¸ƒï¼ˆTop{topk}, çª—å£{window}å¤©ï¼‰")
    plt.xlabel("æœªæ¥å¯¹æ•°æ”¶ç›Š")
    plt.ylabel("æ¬¡æ•°")
    plt.tight_layout()
    plt.savefig(hist_path, dpi=150)
    plt.close()

    return SimilarPack(table=table, dist=dist, hist_path=hist_path)


@dataclass
class ClusterPack:
    df_state: pd.DataFrame
    state_means: pd.DataFrame


def cluster_market_states(df: pd.DataFrame, k: int = 6) -> ClusterPack:
    feats = ["ret", "vol_7d", "vol_30d", "trend_30d"]
    X = df[feats].values
    Xs = StandardScaler().fit_transform(X)

    km = KMeans(n_clusters=k, random_state=42, n_init="auto")
    labels = km.fit_predict(Xs)

    df_state = df.copy()
    df_state["çŠ¶æ€"] = labels

    means = df_state.groupby("çŠ¶æ€")[feats].mean().reset_index()
    means = means.rename(columns={
        "ret": "æ—¥æ”¶ç›Šå‡å€¼",
        "vol_7d": "7æ—¥æ³¢åŠ¨å‡å€¼",
        "vol_30d": "30æ—¥æ³¢åŠ¨å‡å€¼",
        "trend_30d": "30æ—¥è¶‹åŠ¿å‡å€¼",
    })
    return ClusterPack(df_state=df_state, state_means=means)


def risk_by_state(df_state: pd.DataFrame, horizon: int = 10) -> Tuple[pd.DataFrame, int]:
    df = df_state.copy()
    df["æœªæ¥æ”¶ç›Š"] = df["ret"].rolling(horizon).sum().shift(-horizon)
    df = df.dropna(subset=["æœªæ¥æ”¶ç›Š"]).reset_index(drop=True)

    g = df.groupby("çŠ¶æ€")["æœªæ¥æ”¶ç›Š"]
    risk = pd.DataFrame({
        "çŠ¶æ€": g.size().index,
        "æ ·æœ¬æ•°": g.size().values,
        "å‡å€¼": g.mean().values,
        "èƒœç‡(>0)": g.apply(lambda x: float((x > 0).mean())).values,
        "p10(æ›´çœ‹é£é™©)": g.quantile(0.10).values,
        "p25": g.quantile(0.25).values,
        "min(æœ€å·®)": g.min().values,
        "max(æœ€å¥½)": g.max().values,
    })

    risk = risk.sort_values(["å‡å€¼", "p10(æ›´çœ‹é£é™©)", "èƒœç‡(>0)"], ascending=[True, True, True]).reset_index(drop=True)
    worst_state = int(risk.iloc[0]["çŠ¶æ€"])
    return risk, worst_state


# ----------------------------
# 3) æŠ¥å‘Šï¼šæœ¯è¯­é™„å½•
# ----------------------------
def glossary_section() -> str:
    lines = []
    lines.append("\n\n---\n")
    lines.append("## ğŸ“˜ é™„å½•ï¼šæŠ¥å‘Šæœ¯è¯­ç™½è¯è§£é‡Šï¼ˆç»™ä¸æ‡‚é‡åŒ–çš„è¯»è€…ï¼‰\n")

    lines.append("### é‡åŒ–åˆ†æ\n")
    lines.append("ç”¨æ•°æ®å’Œç»Ÿè®¡æ–¹æ³•çº¦æŸåˆ¤æ–­ï¼Œä¸é æ„Ÿè§‰ï¼›è¿™ä»½æŠ¥å‘Šä¸åšâ€œæ–¹å‘é¢„æµ‹â€ã€‚\n\n")

    lines.append("### åˆ†å¸ƒ\n")
    lines.append("ä¸æ˜¯ä¸€ä¸ªç»“æœï¼Œè€Œæ˜¯ä¸€ç»„å¯èƒ½ç»“æœçš„èŒƒå›´ã€‚å·¦è¾¹é€šå¸¸ä»£è¡¨äºæŸï¼Œå³è¾¹ä»£è¡¨ç›ˆåˆ©ã€‚\n\n")

    lines.append("### å¸‚åœºçŠ¶æ€ / çŠ¶æ€ç¼–å·ï¼ˆk=6ï¼‰\n")
    lines.append("æŠŠå¸‚åœºæŒ‰è¡Œä¸ºç‰¹å¾åˆ†æˆ 6 ç±»ç¯å¢ƒï¼›ç¼–å·åªæ˜¯æ ‡ç­¾ï¼Œæ˜¯å¦å±é™©è¦çœ‹é£é™©ç»Ÿè®¡ã€‚\n\n")

    lines.append("### æ³¢åŠ¨ï¼ˆ7æ—¥/30æ—¥ï¼‰\n")
    lines.append("ä»·æ ¼ä¸Šä¸‹æ™ƒåŠ¨çš„å‰§çƒˆç¨‹åº¦ã€‚æ³¢åŠ¨è¶Šå¤§ï¼ŒçŸ­æœŸè¶Šä¸ç¨³å®šã€‚\n\n")

    lines.append("### è¶‹åŠ¿ï¼ˆ30æ—¥è¶‹åŠ¿ï¼‰\n")
    lines.append("æœ€è¿‘ 30 å¤©æ•´ä½“åå‘ä¸Šæ¶¨è¿˜æ˜¯ä¸‹è·Œã€‚\n\n")

    lines.append("### æœªæ¥çª—å£ï¼ˆhorizonï¼Œå¦‚æœªæ¥10å¤©ï¼‰\n")
    lines.append("ç”¨æ¥ç»Ÿè®¡â€œç±»ä¼¼æƒ…å†µä¸‹åé¢é€šå¸¸å‘ç”Ÿä»€ä¹ˆâ€ï¼Œä¸æ˜¯é¢„æµ‹ã€‚\n\n")

    lines.append("### p10ï¼ˆ10%åˆ†ä½æ•°ï¼‰/ minï¼ˆæœ€å·®ï¼‰\n")
    lines.append("p10 è¡¨ç¤ºæœ€å·®çš„ 10% æƒ…å†µé€šå¸¸ä¼šäºå¤šå°‘ï¼›min æ˜¯å†å²æœ€æç«¯ä¸€æ¬¡äºæŸï¼Œç”¨æ¥ç†è§£å·¦å°¾é£é™©ã€‚\n\n")

    lines.append("### æœ€å®¹æ˜“äºé’±çš„çŠ¶æ€\n")
    lines.append("ç»¼åˆå‡å€¼ã€p10ã€èƒœç‡åå†å²ä¸Šæ›´ä¸å‹å¥½çš„ç¯å¢ƒï¼Œä¸ä»£è¡¨å¿…äºï¼Œåªè¡¨ç¤ºæ›´å®¹æ˜“å‡ºç°ä¸åˆ©åˆ†å¸ƒã€‚\n\n")

    lines.append("### å¦‚ä½•ç”¨è¿™ä»½æŠ¥å‘Š\n")
    lines.append("å®ƒä¸æ˜¯å‘Šè¯‰ä½ æ€ä¹ˆèµ¢ï¼Œè€Œæ˜¯å¸®åŠ©ä½ é¿å…åœ¨å†å²ä¸Šä¸å‹å¥½çš„ç¯å¢ƒé‡Œåšæ¿€è¿›å†³ç­–ã€‚\n")

    return "".join(lines)


# ----------------------------
# 4) æŠ¥å‘Šç”Ÿæˆï¼ˆMarkdown + å›¾ç‰‡å¼•ç”¨ï¼‰
# ----------------------------
def generate_report(
    csv_path: Path,
    out_dir: Path,
    k: int,
    window: int,
    topk: int,
    horizon: int,
) -> Tuple[Path, str]:
    df = load_and_features(csv_path)
    latest_date = df["date"].iloc[-1].date()
    report_date = str(latest_date)

    base = basic_summary(df)

    cluster = cluster_market_states(df, k=k)
    current_state = int(cluster.df_state.iloc[-1]["çŠ¶æ€"])

    risk_table, worst_state = risk_by_state(cluster.df_state, horizon=horizon)

    sim = similar_windows_future_dist(
        df=df,
        out_dir=out_dir,
        report_date=report_date,
        window=window,
        topk=topk,
        horizon=horizon,
    )

    now_utc = datetime.now(timezone.utc).strftime("%Y-%m-%d %H:%M:%S UTC")

    lines: List[str] = []
    lines.append("# BTC é‡åŒ–åˆ†æå…¥é—¨ç‰ˆæŠ¥å‘Šï¼ˆç»“æ„ / åˆ†å¸ƒ / é£é™©ï¼‰\n")
    lines.append(f"> ç”Ÿæˆæ—¶é—´ï¼š{now_utc}  ï½œ  æ•°æ®æˆªæ­¢ï¼š{report_date}\n")

    lines.append("## é˜…è¯»æŒ‡å—ï¼ˆç»™ä¸æ‡‚é‡åŒ–çš„äººï¼‰\n")
    lines.append("- è¿™ä»½æŠ¥å‘Š**ä¸é¢„æµ‹ä»·æ ¼**ï¼Œåªå›ç­”ï¼šåœ¨å½“å‰ç¯å¢ƒä¸‹ï¼Œæœªæ¥ç»“æœçš„**åˆ†å¸ƒ**å¤§è‡´å¦‚ä½•ã€‚\n")
    lines.append("- é‡ç‚¹å…³æ³¨ï¼š**p10 / minï¼ˆå·¦å°¾é£é™©ï¼‰**ã€èƒœç‡ã€ä»¥åŠå½“å‰æ˜¯å¦æ¥è¿‘â€œæœ€å®¹æ˜“äºé’±çŠ¶æ€â€ã€‚\n")
    lines.append("- å¦‚æœå½“å‰çŠ¶æ€=æœ€å®¹æ˜“äºé’±çŠ¶æ€ï¼šä¼˜å…ˆè€ƒè™‘**é™ä½é£é™©æš´éœ²**ï¼Œè€Œä¸æ˜¯åŠ å¤§æ“ä½œé¢‘ç‡ã€‚\n")

    lines.append("\n## 0ï¼‰å¸‚åœºåŸºæœ¬ç”»åƒï¼ˆæè¿°ä¸–ç•Œï¼Œä¸åšåˆ¤æ–­ï¼‰\n")
    lines.append(df_to_md_table(base, max_rows=1))

    lines.append("\n\n## 1ï¼‰å¸‚åœºçŠ¶æ€ï¼ˆå¸‚åœºä¸æ˜¯æ¶¨è·Œï¼Œè€Œæ˜¯çŠ¶æ€åˆ‡æ¢ï¼‰\n")
    lines.append(f"- å½“å‰çŠ¶æ€ç¼–å·ï¼š**{current_state}**ï¼ˆk={k}ï¼‰\n")
    lines.append("### å„çŠ¶æ€çš„å¹³å‡ç‰¹å¾ï¼ˆç”¨äºè§£é‡ŠçŠ¶æ€å¤§æ¦‚æ˜¯ä»€ä¹ˆç¯å¢ƒï¼‰\n")
    lines.append(df_to_md_table(cluster.state_means, max_rows=50))

    lines.append("\n\n## 2ï¼‰é£é™©è¯†åˆ«ï¼ˆçœ‹å·¦å°¾ï¼Œè€Œä¸æ˜¯åªçœ‹å‡å€¼ï¼‰\n")
    lines.append(f"- å†å²ä¸Šæœ€å®¹æ˜“äºé’±çš„çŠ¶æ€ç¼–å·ï¼š**{worst_state}**ï¼ˆæŒ‰å‡å€¼+p10+èƒœç‡ç»¼åˆæ’åºï¼‰\n")
    lines.append("### å„çŠ¶æ€æœªæ¥æ”¶ç›Šåˆ†å¸ƒæ‘˜è¦ï¼ˆæœªæ¥çª—å£ä¸º horizon å¤©ï¼‰\n")
    lines.append(df_to_md_table(risk_table, max_rows=50))

    lines.append("\n\n## 3ï¼‰ç›¸ä¼¼è¡Œæƒ… â†’ æœªæ¥åˆ†å¸ƒï¼ˆåˆ†å¸ƒï¼Œä¸æ˜¯é¢„æµ‹ï¼‰\n")
    lines.append("### æœªæ¥æ”¶ç›Šåˆ†å¸ƒæ‘˜è¦ï¼ˆåœ¨â€œæœ€ç›¸ä¼¼çš„å†å²ç‰‡æ®µâ€æ¡ä»¶ä¸‹ï¼‰\n")
    lines.append(df_to_md_table(sim.dist, max_rows=1))

    lines.append("\n\n### æ”¶ç›Šåˆ†å¸ƒç›´æ–¹å›¾\n")
    # ä½¿ç”¨ç›¸å¯¹è·¯å¾„å¼•ç”¨å›¾ç‰‡ï¼Œç¡®ä¿ Markdown å¯æ˜¾ç¤º
    lines.append(f"![ç›¸ä¼¼è¡Œæƒ…ä¸‹æœªæ¥{horizon}å¤©æ”¶ç›Šåˆ†å¸ƒ]({sim.hist_path.name})\n")

    lines.append("\n\n### å†å²æœ€ç›¸ä¼¼çš„è¡Œæƒ…ç‰‡æ®µï¼ˆTop ç›¸ä¼¼åº¦ï¼‰\n")
    lines.append(df_to_md_table(sim.table, max_rows=topk))

    lines.append("\n\n## 4ï¼‰ç»“è®ºæé†’ï¼ˆä¸åšé¢„æµ‹ï¼Œåªåšé£é™©çº¦æŸï¼‰\n")
    if current_state == worst_state:
        lines.append("- **å½“å‰çŠ¶æ€ == æœ€å®¹æ˜“äºé’±çŠ¶æ€**ï¼šå†å²ä¸Šåœ¨è¿™ç§ç¯å¢ƒä¸‹ï¼Œæœªæ¥æ”¶ç›Šåˆ†å¸ƒæ›´ä¸å‹å¥½ï¼Œå»ºè®®ä¼˜å…ˆæ§åˆ¶é£é™©ã€‚\n")
    else:
        lines.append("- å½“å‰çŠ¶æ€ä¸â€œæœ€å®¹æ˜“äºé’±çŠ¶æ€â€ä¸åŒï¼šä¸ä»£è¡¨ä¸€å®šæœ‰åˆ©ï¼Œä½†å†å²ä¸Šé£é™©ç»“æ„ç›¸å¯¹æ²¡é‚£ä¹ˆå·®ã€‚\n")
    lines.append("- ä»»ä½•å•æ¬¡ç»“æœéƒ½å¯èƒ½åç¦»ç»Ÿè®¡åˆ†å¸ƒï¼›æŠ¥å‘Šä»·å€¼åœ¨äºå¸®åŠ©ä½ é¿å…â€œåœ¨ä¸åˆ©ç¯å¢ƒä¸‹é«˜é¢‘å†³ç­–â€ã€‚\n")

    # é™„å½•ï¼šæœ¯è¯­è§£é‡Š
    lines.append(glossary_section())

    ensure_dir(out_dir)
    stable_path = out_dir / "report.md"
    dated_path = out_dir / f"report_{report_date}.md"

    stable_path.write_text("\n".join(lines), encoding="utf-8")
    dated_path.write_text("\n".join(lines), encoding="utf-8")

    return stable_path, report_date


# ----------------------------
# 5) é‚®ä»¶ï¼šMD + HTMLï¼ˆå¯é€‰ PDFï¼‰
# ----------------------------
def md_to_html_simple(md_text: str) -> str:
    """
    Markdown -> HTMLï¼š
    - è‹¥å®‰è£…äº† markdown åº“ï¼Œåˆ™æ”¯æŒæ›´å¥½çš„è¡¨æ ¼æ¸²æŸ“
    - å¦åˆ™ç”¨ <pre> ä¿åº•
    """
    try:
        import markdown  # pip install markdown
        body = markdown.markdown(md_text, extensions=["tables", "fenced_code"])
        return f"""<!doctype html>
<html><head><meta charset="utf-8"><title>BTC Report</title></head>
<body>{body}</body></html>"""
    except Exception:
        safe = md_text.replace("&", "&amp;").replace("<", "&lt;").replace(">", "&gt;")
        return f"""<!doctype html>
<html><head><meta charset="utf-8"><title>BTC Report</title></head>
<body><pre style="white-space:pre-wrap">{safe}</pre></body></html>"""


def try_make_pdf_with_pandoc(md_path: Path, pdf_path: Path) -> bool:
    """
    å°è¯•ç”¨ pandoc æŠŠ md è½¬ pdfï¼ˆå¯é€‰ï¼‰ã€‚
    æˆåŠŸè¿”å› Trueï¼Œå¦åˆ™ Falseï¼ˆä¸ä¼šè®©ç¨‹åºå¤±è´¥ï¼‰ã€‚
    """
    try:
        subprocess.run(
            ["pandoc", str(md_path), "-o", str(pdf_path)],
            check=True,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
        )
        return True
    except Exception:
        return False


# def send_email_gmail(subject: str, body_text: str, attachments: List[Path]) -> None:
#     """
#     Gmail SMTP SSL 465 å‘é€é‚®ä»¶ã€‚
#     ä»ç¯å¢ƒå˜é‡å–ï¼š
#       SMTP_USER / SMTP_PASS / TO_EMAIL
#     """
#     smtp_user = (os.getenv("SMTP_USER") or "").strip()
#     smtp_pass = (os.getenv("SMTP_PASS") or "").strip()
#     to_email = (os.getenv("TO_EMAIL") or "").strip()

#     if not smtp_user or not smtp_pass or not to_email:
#         raise RuntimeError("ç¼ºå°‘ç¯å¢ƒå˜é‡ï¼šSMTP_USER / SMTP_PASS / TO_EMAILï¼ˆå»ºè®®ç”¨ .env é…ç½®ï¼‰")

#     msg = smtplib.email.message.EmailMessage()  # type: ignore[attr-defined]
#     # å…¼å®¹æ—§ç‰ˆæœ¬ï¼šå¦‚æœä¸Šé¢æŠ¥é”™ï¼Œå°±èµ° MIMEMultipart
#     try:
#         from email.message import EmailMessage
#         msg = EmailMessage()
#         msg["From"] = smtp_user
#         msg["To"] = to_email
#         msg["Subject"] = subject
#         msg.set_content(body_text)

#         for p in attachments:
#             if not p.exists():
#                 continue
#             data = p.read_bytes()
#             # ç®€å•æŒ‰æ‰©å±•åè®¾ç½®ç±»å‹
#             ext = p.suffix.lower()
#             if ext == ".md":
#                 maintype, subtype = "text", "markdown"
#             elif ext == ".html":
#                 maintype, subtype = "text", "html"
#             elif ext == ".pdf":
#                 maintype, subtype = "application", "pdf"
#             elif ext == ".png":
#                 maintype, subtype = "image", "png"
#             else:
#                 maintype, subtype = "application", "octet-stream"
#             msg.add_attachment(data, maintype=maintype, subtype=subtype, filename=p.name)

#         context = ssl.create_default_context()
#         with smtplib.SMTP_SSL("smtp.gmail.com", 465, context=context) as server:
#             server.login(smtp_user, smtp_pass)
#             server.send_message(msg)
#         return

#     except Exception:
#         # å›é€€åˆ°æ›´ä¼ ç»Ÿçš„ MIME æ–¹å¼
#         from email.mime.text import MIMEText
#         from email.mime.multipart import MIMEMultipart
#         from email.mime.application import MIMEApplication

#         m = MIMEMultipart()
#         m["From"] = smtp_user
#         m["To"] = to_email
#         m["Subject"] = subject
#         m.attach(MIMEText(body_text, "plain", "utf-8"))

#         for p in attachments:
#             if not p.exists():
#                 continue
#             part = MIMEApplication(p.read_bytes(), Name=p.name)
#             part["Content-Disposition"] = f'attachment; filename="{p.name}"'
#             m.attach(part)

#         context = ssl.create_default_context()
#         with smtplib.SMTP_SSL("smtp.gmail.com", 465, context=context) as server:
#             server.login(smtp_user, smtp_pass)
#             server.sendmail(smtp_user, [to_email], m.as_string())


# def email_report_after_generated(out_dir: Path, report_date: str) -> None:
#     """
#     å‘é€é™„ä»¶ï¼š
#     - å¿…å‘ï¼šreport_YYYY-MM-DD.mdï¼ˆæˆ– report.mdï¼‰
#     - é™„åŠ ï¼šreport_YYYY-MM-DD.htmlï¼ˆè‡ªåŠ¨ç”Ÿæˆï¼‰
#     - å¯é€‰ï¼šreport_YYYY-MM-DD.pdfï¼ˆè‹¥ pandoc å¯ç”¨ï¼‰
#     """
#     md_path = out_dir / f"report_{report_date}.md"
#     if not md_path.exists():
#         md_path = out_dir / "report.md"
#     if not md_path.exists():
#         raise FileNotFoundError(f"æ‰¾ä¸åˆ°æŠ¥å‘Šæ–‡ä»¶ï¼š{md_path}")

#     md_text = md_path.read_text(encoding="utf-8", errors="ignore")

#     attachments: List[Path] = [md_path]

#     # HTMLï¼ˆè‡ªåŠ¨ç”Ÿæˆï¼‰
#     html_path = out_dir / f"report_{report_date}.html"
#     html_path.write_text(md_to_html_simple(md_text), encoding="utf-8")
#     attachments.append(html_path)

#     # PDFï¼ˆå¯é€‰ï¼‰
#     pdf_path = out_dir / f"report_{report_date}.pdf"
#     if try_make_pdf_with_pandoc(md_path, pdf_path):
#         attachments.append(pdf_path)

#     subject = f"BTC åˆ†ææŠ¥å‘Š {report_date}"
#     body = (
#         f"ä½ å¥½ï¼Œ\n\n"
#         f"å·²ç”Ÿæˆ BTC åˆ†ææŠ¥å‘Šï¼ˆæ—¥æœŸï¼š{report_date}ï¼‰ã€‚\n"
#         f"- é™„ä»¶ï¼šMarkdown + HTMLï¼ˆè‹¥ç³»ç»Ÿæ”¯æŒåˆ™é™„ PDFï¼‰ã€‚\n\n"
#         f"â€”â€” è‡ªåŠ¨åŒ–æŠ¥å‘Šç³»ç»Ÿ"
#     )

#     send_email_gmail(subject=subject, body_text=body, attachments=attachments)


## inline

from email.message import EmailMessage

def md_to_html_email(md_text: str, inline_hist_cid: str | None = None) -> str:
    """
    Markdown -> HTMLï¼ˆç”¨äºé‚®ä»¶æ­£æ–‡ï¼‰
    - ä¼˜å…ˆä½¿ç”¨ markdown åº“æ¸²æŸ“è¡¨æ ¼
    - å¹¶å¯é€‰ï¼šæŠŠæŠ¥å‘Šé‡Œçš„ç›´æ–¹å›¾æ›¿æ¢æˆå†…åµŒå›¾ç‰‡ï¼ˆcidï¼‰
    """
    # å…ˆæŠŠ markdown ä¸­å¯¹ png çš„å¼•ç”¨æ›¿æ¢æˆ cid
    # ä¾‹å¦‚ï¼š![xxx](future_hist_2026-01-30.png) -> <img src="cid:hist" ...>
    # è¿™é‡Œæˆ‘ä»¬ç”¨ä¸€ä¸ªç®€å•æ›¿æ¢ï¼šåªè¦æä¾› cidï¼Œå°±æŠŠä»»ä½• future_hist_*.png æ›¿æ¢ä¸º cid
    if inline_hist_cid:
        import re
        md_text = re.sub(
            r"!\[([^\]]*)\]\((future_hist_[^)]+\.png)\)",
            r'<p><img alt="\1" src="cid:' + inline_hist_cid + r'" style="max-width:100%;height:auto;"></p>',
            md_text
        )

    try:
        import markdown  # pip install markdown
        body = markdown.markdown(md_text, extensions=["tables", "fenced_code"])
    except Exception:
        safe = md_text.replace("&", "&amp;").replace("<", "&lt;").replace(">", "&gt;")
        body = f"<pre style='white-space:pre-wrap'>{safe}</pre>"

    # åŠ ä¸€ç‚¹æœ€åŸºç¡€çš„ HTML æ ·å¼ï¼Œè®©è¡¨æ ¼å¥½è¯»
    html = f"""<!doctype html>
<html>
<head>
<meta charset="utf-8">
<title>BTC Report</title>
<style>
  body {{ font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Arial, "PingFang SC", "Hiragino Sans GB", "Microsoft YaHei", sans-serif; line-height: 1.5; }}
  table {{ border-collapse: collapse; }}
  th, td {{ border: 1px solid #ddd; padding: 6px 8px; }}
  th {{ background: #f6f6f6; }}
  code, pre {{ background: #f6f8fa; padding: 2px 4px; border-radius: 4px; }}
  pre {{ padding: 10px; overflow-x: auto; }}
</style>
</head>
<body>
{body}
</body>
</html>"""
    return html


def send_email_gmail_inline_report(
    subject: str,
    text_fallback: str,
    html_body: str,
    inline_images: list[tuple[Path, str]] | None = None,  # [(path, cid)]
    attachments: list[Path] | None = None,                # å¯é€‰å¤‡ä»½é™„ä»¶
) -> None:
    """
    Gmail SMTP SSL 465 å‘é€é‚®ä»¶ï¼š
    - é‚®ä»¶æ­£æ–‡ï¼šHTMLï¼ˆå¯è¯»ï¼‰ + çº¯æ–‡æœ¬fallback
    - å¯å†…åµŒå›¾ç‰‡ï¼ˆcidï¼‰
    - å¯é€‰é™„ä»¶ï¼ˆæ¯”å¦‚ md / html / pdf å¤‡ä»½ï¼‰
    """
    smtp_user = (os.getenv("SMTP_USER") or "").strip()
    smtp_pass = (os.getenv("SMTP_PASS") or "").strip()
    to_email = (os.getenv("TO_EMAIL") or "").strip()
    if not smtp_user or not smtp_pass or not to_email:
        raise RuntimeError("ç¼ºå°‘ç¯å¢ƒå˜é‡ï¼šSMTP_USER / SMTP_PASS / TO_EMAILï¼ˆå»ºè®®ç”¨ .env é…ç½®ï¼‰")

    msg = EmailMessage()
    msg["From"] = smtp_user
    msg["To"] = to_email
    msg["Subject"] = subject

    # çº¯æ–‡æœ¬ç‰ˆæœ¬ï¼ˆå½“é‚®ç®±ä¸æ”¯æŒ HTML æ—¶æ˜¾ç¤ºï¼‰
    msg.set_content(text_fallback)

    # HTML æ­£æ–‡
    msg.add_alternative(html_body, subtype="html")

    # å†…åµŒå›¾ç‰‡ï¼šå¿…é¡»åŠ åˆ° HTML é‚£ä¸ªéƒ¨åˆ†é‡Œï¼ˆå³ payload[-1]ï¼‰
    if inline_images:
        html_part = msg.get_payload()[-1]
        for img_path, cid in inline_images:
            if not img_path.exists():
                continue
            data = img_path.read_bytes()
            maintype, subtype = "image", img_path.suffix.lower().lstrip(".") or "png"
            html_part.add_related(data, maintype=maintype, subtype=subtype, cid=f"<{cid}>")

    # å¯é€‰é™„ä»¶ï¼šä½œä¸ºå¤‡ä»½ï¼ˆä½ æƒ³è¦å¯ä¿ç•™ï¼Œä¸æƒ³è¦å¯ä¸åŠ ï¼‰
    for p in (attachments or []):
        if not p.exists():
            continue
        data = p.read_bytes()
        ext = p.suffix.lower()
        if ext == ".md":
            maintype, subtype = "text", "markdown"
        elif ext == ".html":
            maintype, subtype = "text", "html"
        elif ext == ".pdf":
            maintype, subtype = "application", "pdf"
        elif ext == ".png":
            maintype, subtype = "image", "png"
        else:
            maintype, subtype = "application", "octet-stream"
        msg.add_attachment(data, maintype=maintype, subtype=subtype, filename=p.name)

    context = ssl.create_default_context()
    with smtplib.SMTP_SSL("smtp.gmail.com", 465, context=context) as server:
        server.login(smtp_user, smtp_pass)
        server.send_message(msg)


def email_report_as_body(out_dir: Path, report_date: str, attach_backup: bool = False) -> None:
    """
    æŠŠæŠ¥å‘Šå†…å®¹ç›´æ¥ä½œä¸ºé‚®ä»¶æ­£æ–‡å‘é€ï¼ˆHTML + æ–‡æœ¬å¤‡ä»½ï¼‰ã€‚
    - é»˜è®¤ä¸å‘é™„ä»¶ï¼ˆæ›´åƒæ—¥æŠ¥ï¼‰
    - å¦‚ attach_backup=Trueï¼Œå¯é™„å¸¦ md/html/pdf ä½œä¸ºå¤‡ä»½
    """
    md_path = out_dir / f"report_{report_date}.md"
    if not md_path.exists():
        md_path = out_dir / "report.md"
    if not md_path.exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°æŠ¥å‘Šæ–‡ä»¶ï¼š{md_path}")

    md_text = md_path.read_text(encoding="utf-8", errors="ignore")

    # å†…åµŒç›´æ–¹å›¾
    hist_path = out_dir / f"future_hist_{report_date}.png"
    cid = "hist"
    html = md_to_html_email(md_text, inline_hist_cid=cid if hist_path.exists() else None)

    subject = f"BTC åˆ†ææŠ¥å‘Š {report_date}"
    text_fallback = (
        f"BTC åˆ†ææŠ¥å‘Š {report_date}\n\n"
        f"ä½ çš„é‚®ç®±å®¢æˆ·ç«¯å¯èƒ½ä¸æ”¯æŒ HTML æ˜¾ç¤ºã€‚\n"
        f"è¯·æŸ¥çœ‹é‚®ä»¶ HTML æ­£æ–‡ï¼Œæˆ–å¯ç”¨é™„ä»¶å¤‡ä»½ã€‚\n\n"
        f"---\n\n{md_text}"
    )

    inline_images = []
    if hist_path.exists():
        inline_images.append((hist_path, cid))

    attachments = []
    if attach_backup:
        attachments.append(md_path)
        html_path = out_dir / f"report_{report_date}.html"
        html_path.write_text(html, encoding="utf-8")
        attachments.append(html_path)

        pdf_path = out_dir / f"report_{report_date}.pdf"
        if try_make_pdf_with_pandoc(md_path, pdf_path):
            attachments.append(pdf_path)

    send_email_gmail_inline_report(
        subject=subject,
        text_fallback=text_fallback,
        html_body=html,
        inline_images=inline_images,
        attachments=attachments,
    )



# ----------------------------
# 6) CLI + ä¸»æµç¨‹ï¼šæ›´æ–° -> åˆ†æ -> æŠ¥å‘Š -> é‚®ä»¶
# ----------------------------
def parse_args() -> argparse.Namespace:
    p = argparse.ArgumentParser(description="BTC é‡åŒ–åˆ†æå…¥é—¨ç‰ˆï¼šæ›´æ–°æ•°æ® -> åˆ†æ -> æŠ¥å‘Š -> é‚®ä»¶")
    p.add_argument("--csv", default="./bitcoin_price_history_usd.csv", help="æœ¬åœ° CSV è·¯å¾„ï¼ˆæ ‡å‡†æ ¼å¼ date,price_usdï¼‰")
    p.add_argument("--out-dir", default="./reports", help="è¾“å‡ºç›®å½•ï¼ˆreport.md + å›¾ç‰‡ï¼‰")

    p.add_argument("--k", type=int, default=6, help="çŠ¶æ€èšç±»æ•°é‡ï¼ˆå»ºè®® 5-7ï¼‰")
    p.add_argument("--window", type=int, default=20, help="ç›¸ä¼¼è¡Œæƒ…çª—å£é•¿åº¦ï¼ˆå¤©ï¼‰")
    p.add_argument("--topk", type=int, default=12, help="æœ€ç›¸ä¼¼çª—å£æ•°é‡")
    p.add_argument("--horizon", type=int, default=10, help="æœªæ¥åˆ†å¸ƒç»Ÿè®¡çª—å£ï¼ˆå¤©ï¼‰")

    p.add_argument("--no-email", action="store_true", help="åªç”ŸæˆæŠ¥å‘Šï¼Œä¸å‘é‚®ä»¶")
    p.add_argument("--no-update", action="store_true", help="ä¸æ›´æ–°æ•°æ®ï¼Œç›´æ¥ç”¨æœ¬åœ° CSV åšåˆ†æï¼ˆè°ƒè¯•ç”¨ï¼‰")
    return p.parse_args()


def main() -> None:
    args = parse_args()

    csv_path = Path(args.csv).expanduser().resolve()
    out_dir = Path(args.out_dir).expanduser().resolve()

    if args.k < 2 or args.k > 20:
        raise ValueError("--k å»ºè®®åœ¨ 2~20")
    if args.window < 5 or args.window > 120:
        raise ValueError("--window å»ºè®®åœ¨ 5~120")
    if args.topk < 3:
        raise ValueError("--topk è‡³å°‘ 3")
    if args.horizon < 1 or args.horizon > 60:
        raise ValueError("--horizon å»ºè®®åœ¨ 1~60")

    # 1) æ›´æ–°æ•°æ®ï¼ˆStooq -> æ ‡å‡†åŒ– -> åˆå¹¶ï¼‰
    if not args.no_update:
        #df_price, updated = update_price_csv(csv_path)
        df_price, updated, source_note = update_price_csv(csv_path)
        print(f"âœ… æ•°æ®å·²å°±ç»ªï¼š{csv_path}ï¼ˆ{'æœ‰æ›´æ–°' if updated else 'æ— æ–°å¢'}ï¼Œå…± {len(df_price)} è¡Œï¼›æ•°æ®æºï¼š{source_note}ï¼‰")
        #print(f"âœ… æ•°æ®å·²å°±ç»ªï¼š{csv_path}ï¼ˆ{'æœ‰æ›´æ–°' if updated else 'æ— æ–°å¢'}ï¼Œå…± {len(df_price)} è¡Œï¼‰")
    else:
        if not csv_path.exists():
            raise FileNotFoundError(f"--no-update æ¨¡å¼ä¸‹æ‰¾ä¸åˆ° CSVï¼š{csv_path}")
        print(f"â„¹ï¸ è·³è¿‡æ›´æ–°ï¼Œç›´æ¥ä½¿ç”¨æœ¬åœ° CSVï¼š{csv_path}")

    # 2) åˆ†æå¹¶ç”ŸæˆæŠ¥å‘Š
    report_path, report_date = generate_report(
        csv_path=csv_path,
        out_dir=out_dir,
        k=args.k,
        window=args.window,
        topk=args.topk,
        horizon=args.horizon,
    )
    print(f"âœ… æŠ¥å‘Šå·²ç”Ÿæˆï¼š{report_path}ï¼ˆæ—¥æœŸï¼š{report_date}ï¼‰")

    # 3) å‘é€é‚®ä»¶
    if not args.no_email:
        #email_report_after_generated(out_dir=out_dir, report_date=report_date)
        email_report_as_body(out_dir=out_dir, report_date=report_date, attach_backup=True)
        print("ğŸ“© é‚®ä»¶å·²å‘é€")
    else:
        print("â„¹ï¸ --no-email å·²å¯ç”¨ï¼šä¸å‘é€é‚®ä»¶")


if __name__ == "__main__":
    main()
